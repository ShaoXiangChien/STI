{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "\n",
    "\n",
    "def clean_df(df):\n",
    "    for index, row in df.iterrows():\n",
    "        row['paragraph'] = re.sub(row['title']+'\\n', '', row['paragraph'])\n",
    "        if row['source'] == 'udn.com':\n",
    "            udn_expert_eyes = re.compile('【專家之眼】')\n",
    "            udn_news_type = re.compile('.+／')\n",
    "            udn_udn = re.compile('聯合新聞網')\n",
    "            udn_listen_start = re.compile('0:00 / 0:00\\n')\n",
    "            udn_end1 = re.compile('延伸閱讀')\n",
    "            udn_end2 = re.compile('（綜合報導）')\n",
    "            udn_news_info = re.compile('〔記者.+／.+報導〕')\n",
    "            udn_keep_reading=re.compile('...繼續閱讀')\n",
    "\n",
    "            row['title'] = re.sub(udn_udn, '', row['title'])\n",
    "            row['title'] = re.sub(udn_expert_eyes, '', row['title'])\n",
    "            row['title'] = re.sub(udn_news_type, '', row['title'])\n",
    "\n",
    "            if udn_listen_start.search(row['paragraph']):\n",
    "                start = udn_listen_start.search(row['paragraph']).span()[1]\n",
    "                row['paragraph'] = row['paragraph'][start:]\n",
    "            if udn_end1.search(row['paragraph']):\n",
    "                stop = udn_end1.search(row['paragraph']).span()[0]\n",
    "                row['paragraph'] = row['paragraph'][:stop]\n",
    "            elif udn_end2.search(row['paragraph']):\n",
    "                stop = udn_end2.search(row['paragraph']).span()[0]\n",
    "                row['paragraph'] = row['paragraph'][:stop]\n",
    "            row['paragraph'] = re.sub(udn_news_info, '', row['paragraph'])\n",
    "            row['paragraph'] = re.sub(udn_keep_reading, '', row['paragraph'])\n",
    "            \n",
    "\n",
    "        elif row['source'] == 'chinatimes.com':\n",
    "            chinatimes_news_type = re.compile('.+》')\n",
    "            chinatimes_end = re.compile('發表意見')\n",
    "\n",
    "            row['title'] = re.sub(chinatimes_news_type, '', row['title'])\n",
    "            if chinatimes_end.search(row['paragraph']):\n",
    "                stop = chinatimes_end.search(row['paragraph']).span()[0]\n",
    "                row['paragraph'] = row['paragraph'][:stop]\n",
    "\n",
    "        elif row['source'] == 'setn.com':\n",
    "            setn_news_info = re.compile('.+報導\\n')\n",
    "            setn_pict = re.compile('（圖／.+）')\n",
    "            setn_vid = re.compile('（請看影片.+）')\n",
    "            setn_url = re.compile('網址：.+')\n",
    "\n",
    "            row['paragraph'] = re.sub(setn_news_info, '', row['paragraph'])\n",
    "            row['paragraph'] = re.sub(setn_pict, '', row['paragraph'])\n",
    "            row['paragraph'] = re.sub(setn_vid, '', row['paragraph'])\n",
    "            row['paragraph'] = re.sub(setn_url, '', row['paragraph'])\n",
    "            row['paragraph'] = row['paragraph'].replace('▲', '')\n",
    "            row['paragraph'] = row['paragraph'].replace('▼', '')\n",
    "\n",
    "        elif row['source'] == 'ltn.com':\n",
    "            ltn_news_type = re.compile('.+》')\n",
    "            ltn_news_info = re.compile('〔.+報導〕')\n",
    "            ltn_break = re.compile('請繼續往下閱讀...\\n')\n",
    "            ltn_end1 = re.compile('☆健康新聞不漏接，按讚追蹤粉絲頁。')\n",
    "            ltn_end2 = re.compile('不用抽 不用搶')\n",
    "\n",
    "            row['title'] = re.sub(ltn_news_type, '', row['title'])\n",
    "            row['paragraph'] = re.sub(ltn_news_info, '', row['paragraph'])\n",
    "            row['paragraph'] = re.sub(ltn_break, '', row['paragraph'])\n",
    "            if ltn_end1.search(row['paragraph']):\n",
    "                stop = ltn_end1.search(row['paragraph']).span()[0]\n",
    "                row['paragraph'] = row['paragraph'][:stop]\n",
    "            elif ltn_end2.search(row['paragraph']):\n",
    "                stop = ltn_end2.search(row['paragraph']).span()[0]\n",
    "                row['paragraph'] = row['paragraph'][:stop]\n",
    "\n",
    "        elif row['source'] == 'appledaily.com':\n",
    "            apple_pict = re.compile('。.+攝\\n')\n",
    "            apple_news_info = re.compile('（.+報導）')\n",
    "            apple_edit = re.compile('（新增：.+）\\n')\n",
    "            applle_update_time = re.compile('更新時間.+')  # 尚未使用\n",
    "\n",
    "            row['paragraph'] = re.sub(apple_pict, '', row['paragraph'])\n",
    "            row['paragraph'] = re.sub(apple_edit, '', row['paragraph'])\n",
    "            if apple_news_info.search(row['paragraph']):\n",
    "                stop = apple_news_info.search(row['paragraph']).span()[0]\n",
    "                row['paragraph'] = row['paragraph'][:stop]\n",
    "\n",
    "        elif row['source'] == 'news.yahoo.com':\n",
    "            # Yahoo新聞為轉載各大新聞網站之新聞，因此種類眾多\n",
    "            yahoo_news_type1 = re.compile('.+／')\n",
    "            yahoo_news_type2 = re.compile('【.+】')\n",
    "            yahoo_newtalk = re.compile('[新頭殼newtalk]\\s*')\n",
    "            yahoo_news_info1 = re.compile('.+ / .+報導\\n')\n",
    "            yahoo_news_info2 = re.compile('（.+／.+報導）\\n')\n",
    "            yahoo_news_info3 = re.compile('讀者投書：.+\\n')\n",
    "            yahoo_news_info4 = re.compile('文 ／.+\\n')\n",
    "            yahoo_news_info5 = re.compile('（編輯：.+）.+')\n",
    "            yahoo_original_url = re.compile('.*原始網址：.+')\n",
    "            yahoo_end1 = re.compile('【網路溫度計調查結果之圖文，未經授權請勿轉載、改寫】')\n",
    "            yahoo_end2 = re.compile('《更多.*報導》')\n",
    "            yahoo_end3 = re.compile('更多.*報導')\n",
    "            yahoo_end4 = re.compile('＿{3,}')\n",
    "            yahoo_end5 = re.compile('延伸閱讀》.+')\n",
    "            yahoo_end6 = re.compile('更多相關新聞\\n')\n",
    "            yahoo_end7 = re.compile('更多.*文章')\n",
    "            yahoo_pict1 = re.compile('.*(.*圖/.+)\\n|.*(.*圖／.+)\\n')\n",
    "            yahoo_pict2 = re.compile('照片來源：.+\\n')\n",
    "\n",
    "            row['title'] = re.sub(yahoo_news_type1, '', row['title'])\n",
    "            row['title'] = re.sub(yahoo_news_type2, '', row['title'])\n",
    "\n",
    "            if yahoo_end1.search(row['paragraph']):\n",
    "                end = yahoo_end1.search(row['paragraph']).span()[0]\n",
    "                row['paragraph'] = row['paragraph'][:end]\n",
    "            elif yahoo_end2.search(row['paragraph']):\n",
    "                end = yahoo_end2.search(row['paragraph']).span()[0]\n",
    "                row['paragraph'] = row['paragraph'][:end]\n",
    "            elif yahoo_end3.search(row['paragraph']):\n",
    "                end = yahoo_end3.search(row['paragraph']).span()[0]\n",
    "                row['paragraph'] = row['paragraph'][:end]\n",
    "            elif yahoo_end4.search(row['paragraph']):\n",
    "                end = yahoo_end4.search(row['paragraph']).span()[0]\n",
    "                row['paragraph'] = row['paragraph'][:end]\n",
    "            elif yahoo_end5.search(row['paragraph']):\n",
    "                end = yahoo_end5.search(row['paragraph']).span()[0]\n",
    "                row['paragraph'] = row['paragraph'][:end]\n",
    "            elif yahoo_end6.search(row['paragraph']):\n",
    "                end = yahoo_end6.search(row['paragraph']).span()[0]\n",
    "                row['paragraph'] = row['paragraph'][:end]\n",
    "            elif yahoo_end7.search(row['paragraph']):\n",
    "                end = yahoo_end7.search(row['paragraph']).span()[0]\n",
    "                row['paragraph'] = row['paragraph'][:end]\n",
    "\n",
    "            row['paragraph'] = re.sub(yahoo_news_info1, '', row['paragraph'])\n",
    "            row['paragraph'] = re.sub(yahoo_news_info2, '', row['paragraph'])\n",
    "            row['paragraph'] = re.sub(yahoo_news_info3, '', row['paragraph'])\n",
    "            row['paragraph'] = re.sub(yahoo_news_info4, '', row['paragraph'])\n",
    "            row['paragraph'] = re.sub(yahoo_news_info5, '', row['paragraph'])\n",
    "            row['paragraph'] = re.sub(yahoo_original_url, '', row['paragraph'])\n",
    "            row['paragraph'] = re.sub(yahoo_newtalk, '', row['paragraph'])\n",
    "            row['paragraph'] = re.sub(yahoo_pict1, '', row['paragraph'])\n",
    "            row['paragraph'] = re.sub(yahoo_pict2, '', row['paragraph'])\n",
    "\n",
    "        elif row['source'] == 'storm.mg':\n",
    "            storm_news_type1 = re.compile('.+：')\n",
    "            storm_news_type2 = re.compile('-新新聞')\n",
    "            storm_news_type3 = re.compile('.+》')\n",
    "            storm_timestamp = re.compile('\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d')\n",
    "            storm_pict = re.compile('（.+照，.+攝）')\n",
    "\n",
    "            row['title'] = re.sub(storm_news_type1, '', row['title'])\n",
    "            row['title'] = re.sub(storm_news_type2, '', row['title'])\n",
    "            row['title'] = re.sub(storm_news_type3, '', row['title'])\n",
    "            if storm_timestamp.search(row['paragraph']):\n",
    "                time = storm_timestamp.search(row['paragraph']).group()\n",
    "                row['paragraph'] = re.sub(\n",
    "                    storm_timestamp, '', row['paragraph'], 1)\n",
    "                if math.isnan(row['date']):\n",
    "                    row['date'] = time\n",
    "            row['paragraph'] = re.sub(storm_pict, '', row['paragraph'])\n",
    "\n",
    "        elif row['source'] == 'cna.com.tw':\n",
    "            continue\n",
    "    return df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
